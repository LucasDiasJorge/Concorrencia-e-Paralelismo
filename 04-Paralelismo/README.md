# âš¡ Paralelismo

Enquanto concorrÃªncia Ã© sobre **estrutura** do programa, paralelismo Ã© sobre **performance**. Aqui vocÃª vai aprender a dividir trabalho entre mÃºltiplos cores para acelerar computaÃ§Ãµes.

---

## ğŸ“‚ ConteÃºdo

### [Divide-and-Conquer/](Divide-and-Conquer/)
ImplementaÃ§Ã£o de busca linear paralela usando o paradigma **dividir para conquistar**.

**O que vocÃª encontra:**
- Busca linear paralelizada com pthreads
- Benchmarks comparando 1, 4, 8 e 16 threads
- AnÃ¡lise de overhead de criaÃ§Ã£o de threads
- DiscussÃ£o sobre quando paralelizar vale a pena

**Resultados de benchmark:**
| Threads | Tempo |
|---------|-------|
| 1 | 4.335s |
| 4 | 1.258s |
| 8 | 0.851s |
| 16 | 0.209s |

### [OpenMP/](OpenMP/)
Exemplos usando **OpenMP** para paralelizaÃ§Ã£o automÃ¡tica de loops.

**O que vocÃª encontra:**
- `parallel_search.cpp` â€” Busca paralela com diretivas OpenMP
- `count_sort_parallel.cpp` â€” Counting Sort paralelizado
- DiscussÃ£o sobre limitaÃ§Ãµes de paralelizaÃ§Ã£o em certos algoritmos

---

## ğŸ¯ O que vocÃª vai aprender aqui

1. **Divide and Conquer** â€” Dividir problema em partes menores
2. **Data Parallelism** â€” Mesma operaÃ§Ã£o em dados diferentes
3. **OpenMP** â€” ParalelizaÃ§Ã£o declarativa em C/C++
4. **Speedup e EficiÃªncia** â€” MÃ©tricas de ganho
5. **Lei de Amdahl** â€” Limite teÃ³rico de paralelizaÃ§Ã£o

---

## ğŸ“Š Lei de Amdahl

Nem todo cÃ³digo pode ser paralelizado. A Lei de Amdahl define o limite:

```
Speedup mÃ¡ximo = 1 / (S + P/N)

S = fraÃ§Ã£o sequencial (nÃ£o paralelizÃ¡vel)
P = fraÃ§Ã£o paralela
N = nÃºmero de processadores
```

**Exemplo:**
- Se 90% do cÃ³digo Ã© paralelo (P=0.9, S=0.1)
- Com 4 cores: Speedup = 1/(0.1 + 0.9/4) = **3.08x**
- Com infinitos cores: Speedup mÃ¡ximo = 1/0.1 = **10x**

> O gargalo sempre serÃ¡ a parte sequencial!

---

## ğŸ”§ OpenMP BÃ¡sico

```cpp
#include <omp.h>

// Paralelizar um loop simples
#pragma omp parallel for
for (int i = 0; i < N; i++) {
    process(data[i]);
}

// Definir nÃºmero de threads
#pragma omp parallel for num_threads(4)
for (int i = 0; i < N; i++) {
    process(data[i]);
}

// ReduÃ§Ã£o (soma paralela)
int sum = 0;
#pragma omp parallel for reduction(+:sum)
for (int i = 0; i < N; i++) {
    sum += data[i];
}
```

---

## âš ï¸ Quando NÃƒO paralelizar

1. **Dados pequenos** â€” Overhead de threads > ganho
2. **DependÃªncias entre iteraÃ§Ãµes** â€” Resultado de uma afeta outra
3. **I/O bound** â€” Gargalo nÃ£o Ã© CPU
4. **Muita sincronizaÃ§Ã£o necessÃ¡ria** â€” Locks matam performance

```cpp
// âŒ NÃƒO pode ser paralelizado facilmente
for (int i = 1; i < N; i++) {
    data[i] = data[i-1] * 2;  // depende do anterior!
}

// âœ… PODE ser paralelizado
for (int i = 0; i < N; i++) {
    data[i] = data[i] * 2;  // independente!
}
```

---

## ğŸ“– Ordem de estudo sugerida

1. Leia o README de [Divide-and-Conquer/](Divide-and-Conquer/) â€” entenda a motivaÃ§Ã£o
2. Analise o cÃ³digo e os benchmarks
3. Experimente com diferentes nÃºmeros de threads
4. Estude os exemplos de [OpenMP/](OpenMP/)
5. Compile e teste variando `num_threads`

---

## ğŸ’¡ Dica prÃ¡tica

> Sempre meÃ§a antes de otimizar. Use ferramentas de profiling para identificar se seu cÃ³digo Ã© CPU-bound e qual parte consome mais tempo.

---

## â¡ï¸ PrÃ³ximo passo

Agora que vocÃª domina os conceitos, veja aplicaÃ§Ãµes prÃ¡ticas em **[05-Estudos-de-Caso/](../05-Estudos-de-Caso/)** com cenÃ¡rios do mundo real.
